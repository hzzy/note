大模型的训练一般分为两个大阶段 
第一个阶段是模型的预训练 
第二阶段微调

## 预训练
通过海量的数据 经过预训练阶段 的到一个预训练模型（pretrained model），这是一个通用的大模型

## 微调
有些能力 通用大模型是不具备的，这时就需要用到一些领域的知识或者自己私有化的数据 来对大模型进行改良 这个过程叫微调。

微调也分为两个大的阶段：
1. SFT （supervise fine turning）
2. 对齐阶段 （alignment）

### SFT
sft阶段 告诉模型我们想要什么 需要一些指令微调数据
```
指令微调数据的格式
（input, output）
（input, output）
（input, output）
......

input 就是用户的问题；
output 标准的答案，一般通过用户标注来获取
```

通过大量的指令微调数据 来对模型进行SFT训练 得到一个训练过的模型 叫 SFT model

### 模型的对齐阶段
需要另一种格式的数据来进行训练 告诉模型我们不想要什么 通过对齐得到的模型 叫aligned model
```
(input, accept, reject)
(input, accept, reject)
(input, accept, reject)
......
```
这种数据可以通过上线后 用户的真实反馈来获取 
对齐的过程 通常有一些常见的方法 PPO 或 DPO
PPO是基于强化学习的训练起来比较有挑战性
DPO 训练过程会简单一些 在对齐阶段比较主流的算法