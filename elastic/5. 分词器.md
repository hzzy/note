# analysis
分词
1. 文本分析是把全文本转换成一系列单词的过程
2. 通过analyzer来实现
3. 可以使用es内置的分词器，也可以定制

## 组成
character filters: 处理原始文本，比如去掉html等标签
tolenizer: 按规则切分字符串
token filters: 切分后的单词二次加工，比如大写转小写

## 测试举例
POST _analyze
{
  "analyzer": "standard",
  "text": "2 running Quick brown-foxed leap over lazy dogs in the sumer evening."
}

# es内置分词器

## standard analyzer

1. 默认分词器
2. 按词切分
3. 小写处理

## simple analyzer
### tokenizer
lower case

1. 按非字母切分 非字母的都被去除
2. 小写处理
## stop analyzer
### tokenizer
lower case
### token filters
stop 
会把the a is等修饰性词语去除

1. 相比simple analyzer 多了stop filter

## whitespace analyzer
### tokenizer
whitespace

1. 按照空格切分

## keyword analyzer
### tokenizer
keyword 

1. 不分词， 直接将输入当一个term输出

## patter analyzer
### tokenizer
pattern
### token filters
lower case
stop

1. 通过正则表达式进行分词
2. 默认\W+, 非字符的符号进行分词

## language analyzer

## customer analyzer

# 社区分词器
ICU
IK
THULAC
